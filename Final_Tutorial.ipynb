{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b056e0f-9fdb-4b0b-a1d4-668caf3c7228",
   "metadata": {},
   "source": [
    "# Final Tutorial\n",
    "### Niko Zhang and Sophie Tsai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c31c7ac-11e0-4705-8a76-38800da01773",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "With the use of prompt engineering, I am never going to write a paragraph ever again.\n",
    "#### ChatGPT prompt:\n",
    "You are a data scientist working in a team conducting exploratory data analysis on crime in the united states at the state level. Your task is to turn in a tutorial that will walk users through the entire data science pipeline: data curation, parsing, and management. You want to see how household income and climate affect the amount of crime rate. You have taken household income data from the census bureau, taken crime data from UCR, and taken climate data from NOAA. Write an introduction to this project so that it shows the purpose of the project, the relevance/importance of the project with supporting background information, and where the data is obtained. Use third person.\n",
    "\n",
    "#### ChatGPT output with some editing:\n",
    "The purpose of this tutorial is to guide readers through the entire data science pipeline, including data curation, parsing, management, and analysis. To provide users with a comprehensive understanding of the data science pipeline, this tutorial conducts exploratory data analysis on crime rates in the United States at the state level. Specifically, it aims to investigate the impact of household income and climate on crime rates.\n",
    "\n",
    "The relevance and importance of this project lies in its potential to provide insights into the factors that contribute to crime rates and how policymakers can use this information to implement effective crime prevention measures. By identifying the key drivers of crime rates, this project could lead to the development of more targeted and effective strategies for reducing crime in the United States.\n",
    "\n",
    "The project uses data from three sources: the U.S. Census Bureau for household income data, the FBI Uniform Crime Reporting (UCR) program for crime data, and the National Oceanic and Atmospheric Administration (NOAA) for climate data. Through this project, we hope to demonstrate the power of data-driven insights in understanding complex social phenomena like crime and informing evidence-based policy decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1efc3d-7f22-4bb0-bd8d-9e96622c2639",
   "metadata": {},
   "source": [
    "## Imports and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e25411d-2fce-44bb-80ed-9122dc8b6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for reading in data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Regex and strings\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Set max rows displayed in DataFrame\n",
    "pd.set_option('display.max_rows', None)\n",
    "# Set max columns displayed in DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# turn off SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24138ed-5e72-4cd7-ba4c-001667001635",
   "metadata": {},
   "source": [
    "## Read in crime data by state (1979-2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f945cd0-4f12-4cd3-aad9-913d75ad5bdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# read in the csv file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m crime_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState_Crime_Rates.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m crime_data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# read in the csv file\n",
    "crime_data = pd.read_csv('State_Crime_Rates.csv')\n",
    "crime_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b12ac405-5b8b-46e8-a43c-8b81db406030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean crime data\n",
    "def clean_crime_data(df, year, version, state_names):\n",
    "    \n",
    "    # version 1 is for datatables in newer format (2005-2019)\n",
    "    if (version == 1):\n",
    "\n",
    "        '''The US state column in the Excel file has merged cells. When reading this file as a \n",
    "        DataFrame, the corresponding column has NaN values due to the merged cells separating \n",
    "        into unmerged cells. The line below fixes the issue by filling in those NaN values\n",
    "        with the correct US states.'''\n",
    "        df[df.columns[0]] = df[df.columns[0]].fillna(method='ffill', axis=0)\n",
    "\n",
    "        # Remove the rows that are not part of the data table\n",
    "        df = df[df.isin(['State Total', 'Total', 'Rate per 100,000 inhabitants']).any(axis=1)]\n",
    "\n",
    "        # Remove unnecessary columns\n",
    "        df = df.iloc[:, :13]\n",
    "\n",
    "        # combine columns at indices 1 and 2\n",
    "        df.iloc[:,1:3] = df.iloc[:,1:3].fillna('')\n",
    "        df.insert(1, 'unit_type', df.iloc[:,2]+df.iloc[:,1])\n",
    "        df.drop(df.columns[2:4], axis=1, inplace=True)\n",
    "\n",
    "        # if number of columns is greater than 12, it means there are 2 columns for rape,\n",
    "        # since the definition of 'rape' was changed at some point in time\n",
    "        if len(df.columns) > 12:\n",
    "            # drop the column for the old definiton of 'rape'\n",
    "            df.drop(df.columns[6], axis=1, inplace=True)\n",
    "\n",
    "        # set column names\n",
    "        df.columns = ['state','unit_type','population','violent_crime','murder_and_nonnegligent_manslaughter','rape','robbery','aggravated_assault','property_crime','burglary','larcenytheft','motor_vehicle_theft']\n",
    "\n",
    "        # add column for year\n",
    "        df.insert(0, 'year', year)\n",
    "\n",
    "        # remove all non-characters from state names\n",
    "        df['state'] = df['state'].str.replace(r'\\d|,', '', regex=True).str.title()\n",
    "\n",
    "        # Reset the indices\n",
    "        df.reset_index(drop=True, inplace=True) \n",
    "    \n",
    "    # version 2 is for datatables in older format (1999-2004)\n",
    "    elif (version == 2):\n",
    "        \n",
    "        # Remove unnecessary columns\n",
    "        if (year < 2003):\n",
    "            df.replace(0, np.nan, inplace=True) # replace all zeros with NaN\n",
    "            df=df.dropna(axis=1,how='all') # drop columns with all NaN values\n",
    "            df.drop(df.columns[2:4], axis=1, inplace=True)\n",
    "            # move total property crime column to correct position\n",
    "            col = df[df.columns[3]]\n",
    "            df.drop(df.columns[3], axis=1, inplace=True)\n",
    "            df.insert(7, 'property_crime', col)\n",
    "        df = df.iloc[:, :11]\n",
    "        \n",
    "        # set column names\n",
    "        df.columns = ['unit_type','population','violent_crime','murder_and_nonnegligent_manslaughter','rape','robbery','aggravated_assault','property_crime','burglary','larcenytheft','motor_vehicle_theft']\n",
    "        \n",
    "        # remove all unnecessary rows\n",
    "        df = df[df.isin(['State Total', 'Total', '   Rate per 100,000 inhabitants']).any(axis=1)]\n",
    "        \n",
    "        # Reset the indices\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # strip spaces from unit_type column from both ends\n",
    "        df['unit_type'] = df['unit_type'].str.strip()\n",
    "        \n",
    "        # add column for states\n",
    "        df.insert(0, 'state', state_names)\n",
    "        \n",
    "        # add column for year\n",
    "        df.insert(0, 'year', year)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e133eab5-ea81-4cd8-a2a2-45a256be5f94",
   "metadata": {},
   "source": [
    "## Read in and clean crime data by state (1999-2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13cd529d-6ed7-4f8f-a810-38113d842e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_80/2795509131.py:20: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  crime_data.loc[:, 'population':] = crime_data.loc[:, 'population':].apply(pd.to_numeric, errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>unit_type</th>\n",
       "      <th>population</th>\n",
       "      <th>violent_crime</th>\n",
       "      <th>murder_and_nonnegligent_manslaughter</th>\n",
       "      <th>rape</th>\n",
       "      <th>robbery</th>\n",
       "      <th>aggravated_assault</th>\n",
       "      <th>property_crime</th>\n",
       "      <th>burglary</th>\n",
       "      <th>larcenytheft</th>\n",
       "      <th>motor_vehicle_theft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>State Total</td>\n",
       "      <td>4370000.0</td>\n",
       "      <td>21421.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>1513.0</td>\n",
       "      <td>5297.0</td>\n",
       "      <td>14266.0</td>\n",
       "      <td>171398.0</td>\n",
       "      <td>38648.0</td>\n",
       "      <td>119616.0</td>\n",
       "      <td>13134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Rate per 100,000 inhabitants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>34.6</td>\n",
       "      <td>121.2</td>\n",
       "      <td>326.5</td>\n",
       "      <td>3922.2</td>\n",
       "      <td>884.4</td>\n",
       "      <td>2737.2</td>\n",
       "      <td>300.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>State Total</td>\n",
       "      <td>619000.0</td>\n",
       "      <td>3909.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>2773.0</td>\n",
       "      <td>23099.0</td>\n",
       "      <td>3787.0</td>\n",
       "      <td>16654.0</td>\n",
       "      <td>2658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Rate per 100,000 inhabitants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>631.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>83.5</td>\n",
       "      <td>91.4</td>\n",
       "      <td>448.0</td>\n",
       "      <td>3731.7</td>\n",
       "      <td>611.8</td>\n",
       "      <td>2690.5</td>\n",
       "      <td>429.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>State Total</td>\n",
       "      <td>4778000.0</td>\n",
       "      <td>26334.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>7288.0</td>\n",
       "      <td>17279.0</td>\n",
       "      <td>255401.0</td>\n",
       "      <td>49423.0</td>\n",
       "      <td>167731.0</td>\n",
       "      <td>38247.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    state                     unit_type  population  violent_crime  \\\n",
       "0  1999  Alabama                   State Total   4370000.0        21421.0   \n",
       "1  1999  Alabama  Rate per 100,000 inhabitants         NaN          490.2   \n",
       "2  1999   Alaska                   State Total    619000.0         3909.0   \n",
       "3  1999   Alaska  Rate per 100,000 inhabitants         NaN          631.5   \n",
       "4  1999  Arizona                   State Total   4778000.0        26334.0   \n",
       "\n",
       "   murder_and_nonnegligent_manslaughter    rape  robbery  aggravated_assault  \\\n",
       "0                                 345.0  1513.0   5297.0             14266.0   \n",
       "1                                   7.9    34.6    121.2               326.5   \n",
       "2                                  53.0   517.0    566.0              2773.0   \n",
       "3                                   8.6    83.5     91.4               448.0   \n",
       "4                                 384.0  1383.0   7288.0             17279.0   \n",
       "\n",
       "   property_crime  burglary  larcenytheft  motor_vehicle_theft  \n",
       "0        171398.0   38648.0      119616.0              13134.0  \n",
       "1          3922.2     884.4        2737.2                300.5  \n",
       "2         23099.0    3787.0       16654.0               2658.0  \n",
       "3          3731.7     611.8        2690.5                429.4  \n",
       "4        255401.0   49423.0      167731.0              38247.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for each crime datatable from 2005-2019, read in the excel file, clean it, and append it to\n",
    "   the DataFrame'''\n",
    "df_list = []\n",
    "for i in range(2005,2020):\n",
    "    df = pd.read_excel('data/crimes_by_state/'+str(i)+'/'+str(i)+'offenses_by_state.xls')\n",
    "    df = clean_crime_data(df, i, 1, None)\n",
    "    df_list.append(df)\n",
    "state_names = df_list[0]['state'].head(104)\n",
    "for i in range(1999,2005):\n",
    "    df = pd.read_excel('data/crimes_by_state/'+str(i)+'/'+str(i)+'offenses_by_state.xls')\n",
    "    df = clean_crime_data(df, i, 2, state_names)\n",
    "    df_list.append(df)    \n",
    "\n",
    "crime_data = pd.concat(df_list)\n",
    "crime_data = crime_data.sort_values(['year', 'state'])\n",
    "# Reset the indices\n",
    "crime_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# convert quantitative data columns to numeric type\n",
    "crime_data.loc[:, 'population':] = crime_data.loc[:, 'population':].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# display the first 5 rows of DataFrame\n",
    "crime_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981aa4f6-0db4-481e-bb58-e154b4c5cda5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read in and clean household income data (1999-2019 with 2021 dollars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a81c58e8-a505-441e-8ffa-6fd6a05dfc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>median_household_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>59134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2000</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>55888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>53936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2002</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>56789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2003</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>55014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year    state  median_household_income\n",
       "15  1999  Alabama                    59134\n",
       "16  2000  Alabama                    55888\n",
       "17  2001  Alabama                    53936\n",
       "18  2002  Alabama                    56789\n",
       "19  2003  Alabama                    55014"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the excel file for household income data with the first column as the index column\n",
    "# with the correct headers\n",
    "household_income_data = pd.read_excel('data/household_income_by_state.xlsx', header=[62,63], index_col=0)\n",
    "\n",
    "# remove the columns for standard error\n",
    "household_income_data.drop(labels='Standard error', axis=1, level=1, inplace=True)\n",
    "\n",
    "# remove the name for the index column\n",
    "household_income_data.index.name = None\n",
    "household_income_data.columns.names = (None,None)\n",
    "\n",
    "# melt the data so that no column names are values\n",
    "household_income_data = household_income_data.reset_index().melt(id_vars='index')\n",
    "\n",
    "# rename the columns\n",
    "household_income_data.rename(columns={'index': 'state','variable_0': 'year',\n",
    "                   'variable_1': 'measurement_type', 'value': 'median_household_income'}, inplace=True)\n",
    "\n",
    "# format the year column\n",
    "household_income_data['year'] = household_income_data['year'].astype(str).str.extract(r'(\\d{4})')\n",
    "\n",
    "# sort rows by state and year\n",
    "household_income_data = household_income_data.sort_values(by=['state', 'year'])\n",
    "\n",
    "# remove all rows with 'United States' in state column\n",
    "household_income_data = household_income_data[~household_income_data['state'].isin(['United States'])]\n",
    "household_income_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# drop measurement_type column from DataFrame\n",
    "household_income_data.drop(labels='measurement_type', axis=1, inplace=True)\n",
    "\n",
    "# swap year and state columns\n",
    "columns_titles = ['year','state','median_household_income']\n",
    "household_income_data=household_income_data.reindex(columns=columns_titles)\n",
    "\n",
    "# convert year column to numeric type\n",
    "household_income_data['year'] = pd.to_numeric(household_income_data['year'])\n",
    "\n",
    "# only keep rows where year is between 1999 and 2019\n",
    "household_income_data = household_income_data[household_income_data['year'] >= 1999]\n",
    "household_income_data = household_income_data[household_income_data['year'] <= 2019]\n",
    "\n",
    "# display first 5 rows of DataFrame\n",
    "household_income_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca0eec9-4bd1-45ce-b1b4-b0a7c326a722",
   "metadata": {},
   "source": [
    "## Merging tables from crime, median household income, and climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6fc34d6-aef9-4b16-bdd2-62cb62994876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>unit_type</th>\n",
       "      <th>population</th>\n",
       "      <th>violent_crime</th>\n",
       "      <th>murder_and_nonnegligent_manslaughter</th>\n",
       "      <th>rape</th>\n",
       "      <th>robbery</th>\n",
       "      <th>aggravated_assault</th>\n",
       "      <th>property_crime</th>\n",
       "      <th>burglary</th>\n",
       "      <th>larcenytheft</th>\n",
       "      <th>motor_vehicle_theft</th>\n",
       "      <th>median_household_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>State Total</td>\n",
       "      <td>4370000.0</td>\n",
       "      <td>21421.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>1513.0</td>\n",
       "      <td>5297.0</td>\n",
       "      <td>14266.0</td>\n",
       "      <td>171398.0</td>\n",
       "      <td>38648.0</td>\n",
       "      <td>119616.0</td>\n",
       "      <td>13134.0</td>\n",
       "      <td>59134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Rate per 100,000 inhabitants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>34.6</td>\n",
       "      <td>121.2</td>\n",
       "      <td>326.5</td>\n",
       "      <td>3922.2</td>\n",
       "      <td>884.4</td>\n",
       "      <td>2737.2</td>\n",
       "      <td>300.5</td>\n",
       "      <td>59134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>State Total</td>\n",
       "      <td>619000.0</td>\n",
       "      <td>3909.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>2773.0</td>\n",
       "      <td>23099.0</td>\n",
       "      <td>3787.0</td>\n",
       "      <td>16654.0</td>\n",
       "      <td>2658.0</td>\n",
       "      <td>83839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Rate per 100,000 inhabitants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>631.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>83.5</td>\n",
       "      <td>91.4</td>\n",
       "      <td>448.0</td>\n",
       "      <td>3731.7</td>\n",
       "      <td>611.8</td>\n",
       "      <td>2690.5</td>\n",
       "      <td>429.4</td>\n",
       "      <td>83839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>State Total</td>\n",
       "      <td>4778000.0</td>\n",
       "      <td>26334.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>7288.0</td>\n",
       "      <td>17279.0</td>\n",
       "      <td>255401.0</td>\n",
       "      <td>49423.0</td>\n",
       "      <td>167731.0</td>\n",
       "      <td>38247.0</td>\n",
       "      <td>60348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    state                     unit_type  population  violent_crime  \\\n",
       "0  1999  Alabama                   State Total   4370000.0        21421.0   \n",
       "1  1999  Alabama  Rate per 100,000 inhabitants         NaN          490.2   \n",
       "2  1999   Alaska                   State Total    619000.0         3909.0   \n",
       "3  1999   Alaska  Rate per 100,000 inhabitants         NaN          631.5   \n",
       "4  1999  Arizona                   State Total   4778000.0        26334.0   \n",
       "\n",
       "   murder_and_nonnegligent_manslaughter    rape  robbery  aggravated_assault  \\\n",
       "0                                 345.0  1513.0   5297.0             14266.0   \n",
       "1                                   7.9    34.6    121.2               326.5   \n",
       "2                                  53.0   517.0    566.0              2773.0   \n",
       "3                                   8.6    83.5     91.4               448.0   \n",
       "4                                 384.0  1383.0   7288.0             17279.0   \n",
       "\n",
       "   property_crime  burglary  larcenytheft  motor_vehicle_theft  \\\n",
       "0        171398.0   38648.0      119616.0              13134.0   \n",
       "1          3922.2     884.4        2737.2                300.5   \n",
       "2         23099.0    3787.0       16654.0               2658.0   \n",
       "3          3731.7     611.8        2690.5                429.4   \n",
       "4        255401.0   49423.0      167731.0              38247.0   \n",
       "\n",
       "   median_household_income  \n",
       "0                    59134  \n",
       "1                    59134  \n",
       "2                    83839  \n",
       "3                    83839  \n",
       "4                    60348  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatable = pd.merge(crime_data, household_income_data, on=['year', 'state'], how='inner')\n",
    "\n",
    "# display first 5 rows of resulting DataFrame\n",
    "datatable.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75884c06-2b32-4828-9f7f-e553ffa63ad0",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c71346-501a-4897-ac40-e9c471b1a299",
   "metadata": {},
   "source": [
    "## Read in and Clean Climate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15242f0-eda2-4921-aecc-d8a54f01293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names=['code','jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3fda71e-3b51-4cae-9df2-72d324a23690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all climate data and set missing values to NaN\n",
    "avg_tmp_data = pd.read_csv('data/climate_data/tmpcst.csv', names=column_names, converters={'code': str}, na_values=['-99.9'])\n",
    "max_tmp_data = pd.read_csv('data/climate_data/tmaxst.csv', names=column_names, converters={'code': str}, na_values=['-99.9'])\n",
    "min_tmp_data = pd.read_csv('data/climate_data/tminst.csv', names=column_names, converters={'code': str}, na_values=['-99.9'])\n",
    "pcp_data = pd.read_csv('data/climate_data/pcpnst.csv', names=column_names, converters={'code': str}, na_values=['-9.99'])\n",
    "pdsi_data = pd.read_csv('data/climate_data/pdsist.csv', names=column_names, converters={'code': str}, na_values=['-99.99'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "031e5d5a-8d28-4b3a-aeec-4cf96b117a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split `code` column into state_code and year sub elements\n",
    "def split_code(df):\n",
    "    df[\"state_code\"] = df[\"code\"].str[:3]\n",
    "    df[\"year\"] = df[\"code\"].str[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16d2e1c7-f908-43f0-ac75-9224b59099ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = [avg_tmp_data, max_tmp_data, min_tmp_data, pcp_data, pdsi_data]\n",
    "\n",
    "# Split code column for each climate dataframe\n",
    "for i in range(len(df_names)):\n",
    "    split_code(df_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60b880b6-ea6c-42d2-9f78-3197401bbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and add column for average annual temperature\n",
    "avg_tmp_data[\"avg_ann_tmp\"] = avg_tmp_data.iloc[:, 1:13].mean(axis=1)\n",
    "\n",
    "# Find and add column for max and min annual temperature\n",
    "max_tmp_data[\"max_ann_tmp\"] = max_tmp_data.iloc[:, 1:13].max(axis=1)\n",
    "min_tmp_data[\"min_ann_tmp\"] = min_tmp_data.iloc[:, 1:13].min(axis=1)\n",
    "\n",
    "# Calculate and add column for annual total precipitation\n",
    "pcp_data[\"total_ann_pcp\"] = pcp_data.iloc[:, 1:13].sum(axis=1)\n",
    "\n",
    "# Calculate and add column for average annual PDSI\n",
    "pdsi_data[\"avg_ann_pdsi\"] = pdsi_data.iloc[:, 1:13].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a8d160d-5d4c-48e2-82ee-844f9d95329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first 13 columns for each climate dataframe\n",
    "for i in range(len(df_names)):\n",
    "    df_names[i].drop(df_names[i].iloc[:, 0:13], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "805c8281-bf39-413c-97ba-03e46984e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all climate data together by state code and year\n",
    "climate_df = pd.merge(avg_tmp_data, max_tmp_data, on=['state_code', 'year'], how='inner')\n",
    "climate_df = pd.merge(climate_df, min_tmp_data, on=['state_code', 'year'], how='inner')\n",
    "climate_df = pd.merge(climate_df, pcp_data, on=['state_code', 'year'], how='inner')\n",
    "climate_df = pd.merge(climate_df, pdsi_data, on=['state_code', 'year'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edaac48a-d912-4133-a814-076e0b430750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read NOAA code table\n",
    "noaa_codes = pd.read_csv('data/climate_data/NOAA_codes.csv', names=[\"state_code\",\"state\"], converters={'state_code': str})\n",
    "\n",
    "# Join climate data with state\n",
    "climate_df = pd.merge(climate_df, noaa_codes, on=['state_code'], how='inner')\n",
    "\n",
    "# Drop state code column\n",
    "climate_df.drop('state_code', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65bc2dba-574b-4fc3-af4b-ddea1de45a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>avg_ann_tmp</th>\n",
       "      <th>max_ann_tmp</th>\n",
       "      <th>min_ann_tmp</th>\n",
       "      <th>total_ann_pcp</th>\n",
       "      <th>avg_ann_pdsi</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1895</td>\n",
       "      <td>61.641667</td>\n",
       "      <td>89.7</td>\n",
       "      <td>26.8</td>\n",
       "      <td>50.40</td>\n",
       "      <td>-0.325833</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1896</td>\n",
       "      <td>64.266667</td>\n",
       "      <td>94.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.16</td>\n",
       "      <td>-2.108333</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1897</td>\n",
       "      <td>64.191667</td>\n",
       "      <td>94.0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>48.36</td>\n",
       "      <td>-3.115000</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1898</td>\n",
       "      <td>62.983333</td>\n",
       "      <td>92.7</td>\n",
       "      <td>32.5</td>\n",
       "      <td>48.84</td>\n",
       "      <td>-2.420000</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1899</td>\n",
       "      <td>63.100000</td>\n",
       "      <td>92.3</td>\n",
       "      <td>28.6</td>\n",
       "      <td>48.39</td>\n",
       "      <td>-1.482500</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  avg_ann_tmp  max_ann_tmp  min_ann_tmp  total_ann_pcp  avg_ann_pdsi  \\\n",
       "0  1895    61.641667         89.7         26.8          50.40     -0.325833   \n",
       "1  1896    64.266667         94.0         34.0          46.16     -2.108333   \n",
       "2  1897    64.191667         94.0         31.4          48.36     -3.115000   \n",
       "3  1898    62.983333         92.7         32.5          48.84     -2.420000   \n",
       "4  1899    63.100000         92.3         28.6          48.39     -1.482500   \n",
       "\n",
       "     state  \n",
       "0  Alabama  \n",
       "1  Alabama  \n",
       "2  Alabama  \n",
       "3  Alabama  \n",
       "4  Alabama  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
