{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b056e0f-9fdb-4b0b-a1d4-668caf3c7228",
   "metadata": {},
   "source": [
    "# Final Tutorial\n",
    "### Niko Zhang and Sophie Tsai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c31c7ac-11e0-4705-8a76-38800da01773",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial, our aim is to guide you through the complete data science pipeline, which includes data curation, exploratory data analysis, hypothesis testing, and machine learning. For this tutorial, we will analyze crime rates in the United States at the state level, exploring the impact of household income and climate on the incidence of crime. Our team has obtained the necessary data from the U.S. Census Bureau for household income, the FBI Uniform Crime Reporting (UCR) program for crime, and the National Oceanic and Atmospheric Administration (NOAA) for climate.\n",
    "\n",
    "### Why is our project relevant?\n",
    "\n",
    "As a team, we understand that crime is a complex issue influenced by various factors, including economic and environmental conditions. According to the [FBI](https://ucr.fbi.gov/hate-crime/2011/resources/variables-affecting-crime), household income and climate are some of the factors that can affect the rate of crime. Through this project, we aim to validate these claims and uncover any correlations between crime rates and household income and climate. The insights gained from this analysis can provide policymakers with valuable information on how to implement effective crime prevention measures.\n",
    "\n",
    "Our team hopes that through this project, we can demonstrate the power of data-driven insights in understanding complex social phenomena like crime and informing evidence-based policy decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1efc3d-7f22-4bb0-bd8d-9e96622c2639",
   "metadata": {},
   "source": [
    "## Imports and configurations for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e25411d-2fce-44bb-80ed-9122dc8b6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for reading in data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Imports for using regex and strings methods\n",
    "import re\n",
    "import string\n",
    "\n",
    "pd.set_option('display.max_rows', None) # Set max rows displayed in DataFrame\n",
    "pd.set_option('display.max_columns', None) # Set max columns displayed in DataFrame\n",
    "\n",
    "# turn off SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223bb242-664e-4f98-9d51-85a184f44787",
   "metadata": {},
   "source": [
    "## Data Curation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad42dcc-db43-4dc4-9811-17bf0a3ffb22",
   "metadata": {},
   "source": [
    "### What is it?\n",
    "Data curation in exploratory data analysis refers to the process of collecting, cleaning, and organizing data so that it is suitable for analysis. This involves identifying and correcting errors in the dataset, removing duplicate or irrelevant information, and transforming the data into a usable format. Data curation is an important part of the data science pipeline as it ensures that the data used for analysis is accurate and relevant to the research question being investigate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70215e03-5ac3-458d-ba2e-28544e737972",
   "metadata": {},
   "source": [
    "### Setup for curating our project's data\n",
    "For our purposes, we obtained the raw data in the form of Excel and CSV files. These files were downloaded and organized in a folder named 'data' within our workspace for easy access.\n",
    "\n",
    "To obtain the necessary Excel files for our crime data from the FBI's UCR program, follow these steps:\n",
    "\n",
    "1. Go to https://www.fbi.gov/how-we-can-help-you/more-fbi-services-and-information/ucr/publications.\n",
    "2. Under the section titled 'Crime in the United States,' look for a list of links for years 1999 to 2019.\n",
    "3. Click on each link from 1999 to 2019 and look for the download link that downloads the table for offenses by US state. Keep in mind that some UCR webpages only allow downloading all the tables at once as a compressed file.\n",
    "4. Click on the download link and move the Excel file containing offenses by US state into our workspace's 'data' folder. We organized our Excel files further by placing each file into a folder for its designated year, but this is optional.\n",
    "\n",
    "To obtain the Excel file for household income, go to https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-income-households.html and click the download link under section 'Table H-8. Median Household Income by State' Move the Excel file into our 'data' folder.\n",
    "\n",
    "All of the climate data was obtained from the National Centers for Environmental Information [(NCEI)](https://www.ncei.noaa.gov/), a long-term archive for all National Oceanic and Atmospheric Administration [(NOAA)](https://www.noaa.gov/) coastal tide gauge data. The datasets can be found at https://www.ncei.noaa.gov/pub/data/cirs/climdiv/.\n",
    "\n",
    "We decided to include five factors at the statewide monthly level that may impact crime incidents, including\n",
    "1. Average temperature (deg. F. to 10ths): *climdiv-tmpcst-vx.y.z-YYYYMMDD*\n",
    "2. Maximum temperature (deg. F. to 10ths): *climdiv-tmaxst-vx.y.z-YYYYMMDD*\n",
    "3. Minimum temperature (deg. F. to 10ths): *climdiv-tminst-vx.y.z-YYYYMMDD*\n",
    "4. Precipitation (inches to 100ths): *climdiv-pcpnst-vx.y.z-YYYYMMDD*\n",
    "5. Palmer Drought Severity Index (PDSI): *climdiv-pdsist-vx.y.z-YYYYMMDD*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24138ed-5e72-4cd7-ba4c-001667001635",
   "metadata": {},
   "source": [
    "### Curating crime data by state (1999-2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8afa2f9-ceae-4349-8f05-b2ead22cafbe",
   "metadata": {},
   "source": [
    "Before beginning, you should always look through the raw data to see if there are any recurring patterns/formats you can exploit to make data curation easier. If we look through the Excel files obtained from FBI's UCR program, you'll find that the data for years 2005-2019 are stored in a different format from the data for years 1999-2004. Because data for years 1999-2019 is stored mostly in the same format, we can create a function that curates the data for us rather than curating each year's data individually. \n",
    "\n",
    "The function below takes in one of our DataFrames from our crime data and curates it based on the two formats that our raw data is stored in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b12ac405-5b8b-46e8-a43c-8b81db406030",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function curates crime data based on the 2 predetermined formats that the data is stored in.\n",
    "df: the DataFrame we want to curate\n",
    "year: the year the data was collected from\n",
    "version: put in 1 for curating data from 2005-2019 (newer format)\n",
    "         put in 2 for curating data from 1999-2004 (older format)\n",
    "state_names: list of state names that need to be appended as a new column to the DataFrames from \n",
    "             years 1999-2004 due to the way the raw data is stored\n",
    "'''\n",
    "def clean_crime_data(df, year, version, state_names):\n",
    "    \n",
    "    # version 1 is for datatables in newer format (2005-2019)\n",
    "    if (version == 1):\n",
    "\n",
    "        '''The US state column in the Excel file has merged cells. When reading this file as a \n",
    "        DataFrame, the corresponding column has NaN values due to the merged cells separating \n",
    "        into unmerged cells. The line below fixes the issue by filling in those NaN values\n",
    "        with the correct US states.'''\n",
    "        df[df.columns[0]] = df[df.columns[0]].fillna(method='ffill', axis=0)\n",
    "\n",
    "        # Remove the rows that are not part of the data table\n",
    "        df = df[df.isin(['State Total', 'Total', 'Rate per 100,000 inhabitants']).any(axis=1)]\n",
    "\n",
    "        # Remove unnecessary columns\n",
    "        df = df.iloc[:, :13]\n",
    "\n",
    "        # combine columns at indices 1 and 2\n",
    "        df.iloc[:,1:3] = df.iloc[:,1:3].fillna('')\n",
    "        df.insert(1, 'unit_type', df.iloc[:,2]+df.iloc[:,1])\n",
    "        df.drop(df.columns[2:4], axis=1, inplace=True)\n",
    "\n",
    "        # if number of columns is greater than 12, it means there are 2 columns for rape,\n",
    "        # since the definition of 'rape' was changed at some point in time\n",
    "        if len(df.columns) > 12:\n",
    "            # drop the column for the old definiton of 'rape'\n",
    "            df.drop(df.columns[6], axis=1, inplace=True)\n",
    "\n",
    "        # set column names\n",
    "        df.columns = ['state','unit_type','population','violent_crime','murder_and_nonnegligent_manslaughter','rape','robbery','aggravated_assault','property_crime','burglary','larcenytheft','motor_vehicle_theft']\n",
    "\n",
    "        # add column for year\n",
    "        df.insert(0, 'year', year)\n",
    "\n",
    "        # remove all non-characters from state names\n",
    "        df['state'] = df['state'].str.replace(r'\\d|,', '', regex=True).str.title()\n",
    "\n",
    "        # Reset the indices\n",
    "        df.reset_index(drop=True, inplace=True) \n",
    "    \n",
    "    # version 2 is for datatables in older format (1999-2004)\n",
    "    elif (version == 2):\n",
    "        \n",
    "        # Remove unnecessary columns\n",
    "        if (year < 2003):\n",
    "            df.replace(0, np.nan, inplace=True) # replace all zeros with NaN\n",
    "            df=df.dropna(axis=1,how='all') # drop columns with all NaN values\n",
    "            df.drop(df.columns[2:4], axis=1, inplace=True)\n",
    "            # move total property crime column to correct position\n",
    "            col = df[df.columns[3]]\n",
    "            df.drop(df.columns[3], axis=1, inplace=True)\n",
    "            df.insert(7, 'property_crime', col)\n",
    "        df = df.iloc[:, :11]\n",
    "        \n",
    "        # set column names\n",
    "        df.columns = ['unit_type','population','violent_crime','murder_and_nonnegligent_manslaughter','rape','robbery','aggravated_assault','property_crime','burglary','larcenytheft','motor_vehicle_theft']\n",
    "        \n",
    "        # remove all unnecessary rows\n",
    "        df = df[df.isin(['State Total', 'Total', '   Rate per 100,000 inhabitants']).any(axis=1)]\n",
    "        \n",
    "        # Reset the indices\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # strip spaces from unit_type column from both ends\n",
    "        df['unit_type'] = df['unit_type'].str.strip()\n",
    "        \n",
    "        # add column for states\n",
    "        df.insert(0, 'state', state_names)\n",
    "        \n",
    "        # add column for year\n",
    "        df.insert(0, 'year', year)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3403c1ca-51dc-4bfb-acd1-d57d6697bb61",
   "metadata": {},
   "source": [
    "## Read In and Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e133eab5-ea81-4cd8-a2a2-45a256be5f94",
   "metadata": {},
   "source": [
    "#### Curating and merging our data\n",
    "With our new function, we are able to curate each of our Excel files by reading in each file as a DataFrame and then curating it based on format in which the raw data is stored. We can then merge the curated DataFrames together into a single DataFrame containing curated data from all years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13cd529d-6ed7-4f8f-a810-38113d842e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_79/2795509131.py:20: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  crime_data.loc[:, 'population':] = crime_data.loc[:, 'population':].apply(pd.to_numeric, errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>unit_type</th>\n",
       "      <th>population</th>\n",
       "      <th>violent_crime</th>\n",
       "      <th>murder_and_nonnegligent_manslaughter</th>\n",
       "      <th>rape</th>\n",
       "      <th>robbery</th>\n",
       "      <th>aggravated_assault</th>\n",
       "      <th>property_crime</th>\n",
       "      <th>burglary</th>\n",
       "      <th>larcenytheft</th>\n",
       "      <th>motor_vehicle_theft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>State Total</td>\n",
       "      <td>4370000.0</td>\n",
       "      <td>21421.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>1513.0</td>\n",
       "      <td>5297.0</td>\n",
       "      <td>14266.0</td>\n",
       "      <td>171398.0</td>\n",
       "      <td>38648.0</td>\n",
       "      <td>119616.0</td>\n",
       "      <td>13134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Rate per 100,000 inhabitants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>34.6</td>\n",
       "      <td>121.2</td>\n",
       "      <td>326.5</td>\n",
       "      <td>3922.2</td>\n",
       "      <td>884.4</td>\n",
       "      <td>2737.2</td>\n",
       "      <td>300.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>State Total</td>\n",
       "      <td>619000.0</td>\n",
       "      <td>3909.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>2773.0</td>\n",
       "      <td>23099.0</td>\n",
       "      <td>3787.0</td>\n",
       "      <td>16654.0</td>\n",
       "      <td>2658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Rate per 100,000 inhabitants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>631.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>83.5</td>\n",
       "      <td>91.4</td>\n",
       "      <td>448.0</td>\n",
       "      <td>3731.7</td>\n",
       "      <td>611.8</td>\n",
       "      <td>2690.5</td>\n",
       "      <td>429.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>State Total</td>\n",
       "      <td>4778000.0</td>\n",
       "      <td>26334.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>7288.0</td>\n",
       "      <td>17279.0</td>\n",
       "      <td>255401.0</td>\n",
       "      <td>49423.0</td>\n",
       "      <td>167731.0</td>\n",
       "      <td>38247.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    state                     unit_type  population  violent_crime  \\\n",
       "0  1999  Alabama                   State Total   4370000.0        21421.0   \n",
       "1  1999  Alabama  Rate per 100,000 inhabitants         NaN          490.2   \n",
       "2  1999   Alaska                   State Total    619000.0         3909.0   \n",
       "3  1999   Alaska  Rate per 100,000 inhabitants         NaN          631.5   \n",
       "4  1999  Arizona                   State Total   4778000.0        26334.0   \n",
       "\n",
       "   murder_and_nonnegligent_manslaughter    rape  robbery  aggravated_assault  \\\n",
       "0                                 345.0  1513.0   5297.0             14266.0   \n",
       "1                                   7.9    34.6    121.2               326.5   \n",
       "2                                  53.0   517.0    566.0              2773.0   \n",
       "3                                   8.6    83.5     91.4               448.0   \n",
       "4                                 384.0  1383.0   7288.0             17279.0   \n",
       "\n",
       "   property_crime  burglary  larcenytheft  motor_vehicle_theft  \n",
       "0        171398.0   38648.0      119616.0              13134.0  \n",
       "1          3922.2     884.4        2737.2                300.5  \n",
       "2         23099.0    3787.0       16654.0               2658.0  \n",
       "3          3731.7     611.8        2690.5                429.4  \n",
       "4        255401.0   49423.0      167731.0              38247.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for each crime datatable from 2005-2019, read in the excel file, clean it, and append it to\n",
    "   the DataFrame'''\n",
    "df_list = []\n",
    "for i in range(2005,2020):\n",
    "    df = pd.read_excel('data/crimes_by_state/'+str(i)+'/'+str(i)+'offenses_by_state.xls')\n",
    "    df = clean_crime_data(df, i, 1, None)\n",
    "    df_list.append(df)\n",
    "state_names = df_list[0]['state'].head(104)\n",
    "for i in range(1999,2005):\n",
    "    df = pd.read_excel('data/crimes_by_state/'+str(i)+'/'+str(i)+'offenses_by_state.xls')\n",
    "    df = clean_crime_data(df, i, 2, state_names)\n",
    "    df_list.append(df)    \n",
    "\n",
    "crime_data = pd.concat(df_list)\n",
    "crime_data = crime_data.sort_values(['year', 'state'])\n",
    "# Reset the indices\n",
    "crime_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# convert quantitative data columns to numeric type\n",
    "crime_data.loc[:, 'population':] = crime_data.loc[:, 'population':].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# display the first 5 rows of DataFrame\n",
    "crime_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981aa4f6-0db4-481e-bb58-e154b4c5cda5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Curating household income data (1999-2019 with 2021 dollars)\n",
    "\n",
    "As there is only one Excel file we need to curate, we simply clean it without using any helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a81c58e8-a505-441e-8ffa-6fd6a05dfc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>median_household_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>59134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2000</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>55888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>53936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2002</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>56789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2003</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>55014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year    state  median_household_income\n",
       "15  1999  Alabama                    59134\n",
       "16  2000  Alabama                    55888\n",
       "17  2001  Alabama                    53936\n",
       "18  2002  Alabama                    56789\n",
       "19  2003  Alabama                    55014"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the excel file for household income data with the first column as the index column\n",
    "# with the correct headers\n",
    "household_income_data = pd.read_excel('data/household_income_by_state.xlsx', header=[62,63], index_col=0)\n",
    "\n",
    "# remove the columns for standard error\n",
    "household_income_data.drop(labels='Standard error', axis=1, level=1, inplace=True)\n",
    "\n",
    "# remove the name for the index column\n",
    "household_income_data.index.name = None\n",
    "household_income_data.columns.names = (None,None)\n",
    "\n",
    "# melt the data so that no column names are values\n",
    "household_income_data = household_income_data.reset_index().melt(id_vars='index')\n",
    "\n",
    "# rename the columns\n",
    "household_income_data.rename(columns={'index': 'state','variable_0': 'year',\n",
    "                   'variable_1': 'measurement_type', 'value': 'median_household_income'}, inplace=True)\n",
    "\n",
    "# format the year column\n",
    "household_income_data['year'] = household_income_data['year'].astype(str).str.extract(r'(\\d{4})')\n",
    "\n",
    "# sort rows by state and year\n",
    "household_income_data = household_income_data.sort_values(by=['state', 'year'])\n",
    "\n",
    "# remove all rows with 'United States' in state column\n",
    "household_income_data = household_income_data[~household_income_data['state'].isin(['United States'])]\n",
    "household_income_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# drop measurement_type column from DataFrame\n",
    "household_income_data.drop(labels='measurement_type', axis=1, inplace=True)\n",
    "\n",
    "# swap year and state columns\n",
    "columns_titles = ['year','state','median_household_income']\n",
    "household_income_data=household_income_data.reindex(columns=columns_titles)\n",
    "\n",
    "# convert year column to numeric type\n",
    "household_income_data['year'] = pd.to_numeric(household_income_data['year'])\n",
    "\n",
    "# only keep rows where year is between 1999 and 2019\n",
    "household_income_data = household_income_data[household_income_data['year'] >= 1999]\n",
    "household_income_data = household_income_data[household_income_data['year'] <= 2019]\n",
    "\n",
    "# display first 5 rows of DataFrame\n",
    "household_income_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c71346-501a-4897-ac40-e9c471b1a299",
   "metadata": {},
   "source": [
    "### Climate data by state (1895-2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3fda71e-3b51-4cae-9df2-72d324a23690",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names=['code','jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "\n",
    "# read all climate data, add corresponding column names, and set missing values to NaN\n",
    "avg_tmp_data = pd.read_csv('data/climate_data/tmpcst.csv', names=column_names, converters={'code': str}, na_values=['-99.9'])\n",
    "max_tmp_data = pd.read_csv('data/climate_data/tmaxst.csv', names=column_names, converters={'code': str}, na_values=['-99.9'])\n",
    "min_tmp_data = pd.read_csv('data/climate_data/tminst.csv', names=column_names, converters={'code': str}, na_values=['-99.9'])\n",
    "pcp_data = pd.read_csv('data/climate_data/pcpnst.csv', names=column_names, converters={'code': str}, na_values=['-9.99'])\n",
    "pdsi_data = pd.read_csv('data/climate_data/pdsist.csv', names=column_names, converters={'code': str}, na_values=['-99.99'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d2e1c7-f908-43f0-ac75-9224b59099ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split `code` column into state_code and year sub elements\n",
    "def split_code(df):\n",
    "    df[\"state_code\"] = df[\"code\"].str[:3]\n",
    "    df[\"year\"] = df[\"code\"].str[6:]\n",
    "    \n",
    "df_names = [avg_tmp_data, max_tmp_data, min_tmp_data, pcp_data, pdsi_data]\n",
    "\n",
    "# split code column for each climate dataframe\n",
    "for i in range(len(df_names)):\n",
    "    split_code(df_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60b880b6-ea6c-42d2-9f78-3197401bbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and add column for average annual temperature\n",
    "avg_tmp_data[\"avg_ann_tmp\"] = avg_tmp_data.iloc[:, 1:13].mean(axis=1)\n",
    "\n",
    "# find and add column for max and min annual temperature\n",
    "max_tmp_data[\"max_ann_tmp\"] = max_tmp_data.iloc[:, 1:13].max(axis=1)\n",
    "min_tmp_data[\"min_ann_tmp\"] = min_tmp_data.iloc[:, 1:13].min(axis=1)\n",
    "\n",
    "# calculate and add column for annual total precipitation\n",
    "pcp_data[\"total_ann_pcp\"] = pcp_data.iloc[:, 1:13].sum(axis=1)\n",
    "\n",
    "# calculate and add column for average annual PDSI\n",
    "pdsi_data[\"avg_ann_pdsi\"] = pdsi_data.iloc[:, 1:13].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a8d160d-5d4c-48e2-82ee-844f9d95329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop first 13 columns for each climate dataframe\n",
    "for i in range(len(df_names)):\n",
    "    df_names[i].drop(df_names[i].iloc[:, 0:13], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "805c8281-bf39-413c-97ba-03e46984e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all climate data together by state code and year\n",
    "climate_df = pd.merge(avg_tmp_data, max_tmp_data, on=['state_code', 'year'], how='inner')\n",
    "climate_df = pd.merge(climate_df, min_tmp_data, on=['state_code', 'year'], how='inner')\n",
    "climate_df = pd.merge(climate_df, pcp_data, on=['state_code', 'year'], how='inner')\n",
    "climate_df = pd.merge(climate_df, pdsi_data, on=['state_code', 'year'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edaac48a-d912-4133-a814-076e0b430750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>avg_ann_tmp</th>\n",
       "      <th>max_ann_tmp</th>\n",
       "      <th>min_ann_tmp</th>\n",
       "      <th>total_ann_pcp</th>\n",
       "      <th>avg_ann_pdsi</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1895</td>\n",
       "      <td>61.641667</td>\n",
       "      <td>89.7</td>\n",
       "      <td>26.8</td>\n",
       "      <td>50.40</td>\n",
       "      <td>-0.325833</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1896</td>\n",
       "      <td>64.266667</td>\n",
       "      <td>94.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.16</td>\n",
       "      <td>-2.108333</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1897</td>\n",
       "      <td>64.191667</td>\n",
       "      <td>94.0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>48.36</td>\n",
       "      <td>-3.115000</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1898</td>\n",
       "      <td>62.983333</td>\n",
       "      <td>92.7</td>\n",
       "      <td>32.5</td>\n",
       "      <td>48.84</td>\n",
       "      <td>-2.420000</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1899</td>\n",
       "      <td>63.100000</td>\n",
       "      <td>92.3</td>\n",
       "      <td>28.6</td>\n",
       "      <td>48.39</td>\n",
       "      <td>-1.482500</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  avg_ann_tmp  max_ann_tmp  min_ann_tmp  total_ann_pcp  avg_ann_pdsi  \\\n",
       "0  1895    61.641667         89.7         26.8          50.40     -0.325833   \n",
       "1  1896    64.266667         94.0         34.0          46.16     -2.108333   \n",
       "2  1897    64.191667         94.0         31.4          48.36     -3.115000   \n",
       "3  1898    62.983333         92.7         32.5          48.84     -2.420000   \n",
       "4  1899    63.100000         92.3         28.6          48.39     -1.482500   \n",
       "\n",
       "     state  \n",
       "0  Alabama  \n",
       "1  Alabama  \n",
       "2  Alabama  \n",
       "3  Alabama  \n",
       "4  Alabama  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read NOAA code table\n",
    "noaa_codes = pd.read_csv('data/climate_data/NOAA_codes.csv', names=[\"state_code\",\"state\"], converters={'state_code': str})\n",
    "\n",
    "# join climate data with state\n",
    "climate_df = pd.merge(climate_df, noaa_codes, on=['state_code'], how='inner')\n",
    "\n",
    "# drop state code column\n",
    "climate_df.drop('state_code', axis=1, inplace=True)\n",
    "\n",
    "# convert year column to int\n",
    "climate_df['year'] = climate_df['year'].astype(int)\n",
    "\n",
    "climate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca0eec9-4bd1-45ce-b1b4-b0a7c326a722",
   "metadata": {},
   "source": [
    "### Merging tables from crime, median household income, and climate data\n",
    "\n",
    "Now that we have cleaned all our data, we need to merge the 3 DataFrames for crime, household income, and climate data into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6fc34d6-aef9-4b16-bdd2-62cb62994876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>unit_type</th>\n",
       "      <th>population</th>\n",
       "      <th>violent_crime</th>\n",
       "      <th>murder_and_nonnegligent_manslaughter</th>\n",
       "      <th>rape</th>\n",
       "      <th>robbery</th>\n",
       "      <th>aggravated_assault</th>\n",
       "      <th>property_crime</th>\n",
       "      <th>burglary</th>\n",
       "      <th>larcenytheft</th>\n",
       "      <th>motor_vehicle_theft</th>\n",
       "      <th>median_household_income</th>\n",
       "      <th>avg_ann_tmp_x</th>\n",
       "      <th>max_ann_tmp_x</th>\n",
       "      <th>min_ann_tmp_x</th>\n",
       "      <th>total_ann_pcp_x</th>\n",
       "      <th>avg_ann_pdsi_x</th>\n",
       "      <th>avg_ann_tmp_y</th>\n",
       "      <th>max_ann_tmp_y</th>\n",
       "      <th>min_ann_tmp_y</th>\n",
       "      <th>total_ann_pcp_y</th>\n",
       "      <th>avg_ann_pdsi_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>State Total</td>\n",
       "      <td>4370000.0</td>\n",
       "      <td>21421.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>1513.0</td>\n",
       "      <td>5297.0</td>\n",
       "      <td>14266.0</td>\n",
       "      <td>171398.0</td>\n",
       "      <td>38648.0</td>\n",
       "      <td>119616.0</td>\n",
       "      <td>13134.0</td>\n",
       "      <td>59134</td>\n",
       "      <td>64.141667</td>\n",
       "      <td>94.2</td>\n",
       "      <td>34.6</td>\n",
       "      <td>49.01</td>\n",
       "      <td>-0.8475</td>\n",
       "      <td>64.141667</td>\n",
       "      <td>94.2</td>\n",
       "      <td>34.6</td>\n",
       "      <td>49.01</td>\n",
       "      <td>-0.8475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Rate per 100,000 inhabitants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>490.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>34.6</td>\n",
       "      <td>121.2</td>\n",
       "      <td>326.5</td>\n",
       "      <td>3922.2</td>\n",
       "      <td>884.4</td>\n",
       "      <td>2737.2</td>\n",
       "      <td>300.5</td>\n",
       "      <td>59134</td>\n",
       "      <td>64.141667</td>\n",
       "      <td>94.2</td>\n",
       "      <td>34.6</td>\n",
       "      <td>49.01</td>\n",
       "      <td>-0.8475</td>\n",
       "      <td>64.141667</td>\n",
       "      <td>94.2</td>\n",
       "      <td>34.6</td>\n",
       "      <td>49.01</td>\n",
       "      <td>-0.8475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>State Total</td>\n",
       "      <td>619000.0</td>\n",
       "      <td>3909.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>2773.0</td>\n",
       "      <td>23099.0</td>\n",
       "      <td>3787.0</td>\n",
       "      <td>16654.0</td>\n",
       "      <td>2658.0</td>\n",
       "      <td>83839</td>\n",
       "      <td>24.041667</td>\n",
       "      <td>61.3</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>40.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.041667</td>\n",
       "      <td>61.3</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>40.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Rate per 100,000 inhabitants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>631.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>83.5</td>\n",
       "      <td>91.4</td>\n",
       "      <td>448.0</td>\n",
       "      <td>3731.7</td>\n",
       "      <td>611.8</td>\n",
       "      <td>2690.5</td>\n",
       "      <td>429.4</td>\n",
       "      <td>83839</td>\n",
       "      <td>24.041667</td>\n",
       "      <td>61.3</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>40.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.041667</td>\n",
       "      <td>61.3</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>40.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>State Total</td>\n",
       "      <td>4778000.0</td>\n",
       "      <td>26334.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>7288.0</td>\n",
       "      <td>17279.0</td>\n",
       "      <td>255401.0</td>\n",
       "      <td>49423.0</td>\n",
       "      <td>167731.0</td>\n",
       "      <td>38247.0</td>\n",
       "      <td>60348</td>\n",
       "      <td>60.783333</td>\n",
       "      <td>91.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.37</td>\n",
       "      <td>-1.2725</td>\n",
       "      <td>60.783333</td>\n",
       "      <td>91.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.37</td>\n",
       "      <td>-1.2725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    state                     unit_type  population  violent_crime  \\\n",
       "0  1999  Alabama                   State Total   4370000.0        21421.0   \n",
       "1  1999  Alabama  Rate per 100,000 inhabitants         NaN          490.2   \n",
       "2  1999   Alaska                   State Total    619000.0         3909.0   \n",
       "3  1999   Alaska  Rate per 100,000 inhabitants         NaN          631.5   \n",
       "4  1999  Arizona                   State Total   4778000.0        26334.0   \n",
       "\n",
       "   murder_and_nonnegligent_manslaughter    rape  robbery  aggravated_assault  \\\n",
       "0                                 345.0  1513.0   5297.0             14266.0   \n",
       "1                                   7.9    34.6    121.2               326.5   \n",
       "2                                  53.0   517.0    566.0              2773.0   \n",
       "3                                   8.6    83.5     91.4               448.0   \n",
       "4                                 384.0  1383.0   7288.0             17279.0   \n",
       "\n",
       "   property_crime  burglary  larcenytheft  motor_vehicle_theft  \\\n",
       "0        171398.0   38648.0      119616.0              13134.0   \n",
       "1          3922.2     884.4        2737.2                300.5   \n",
       "2         23099.0    3787.0       16654.0               2658.0   \n",
       "3          3731.7     611.8        2690.5                429.4   \n",
       "4        255401.0   49423.0      167731.0              38247.0   \n",
       "\n",
       "   median_household_income  avg_ann_tmp_x  max_ann_tmp_x  min_ann_tmp_x  \\\n",
       "0                    59134      64.141667           94.2           34.6   \n",
       "1                    59134      64.141667           94.2           34.6   \n",
       "2                    83839      24.041667           61.3          -11.6   \n",
       "3                    83839      24.041667           61.3          -11.6   \n",
       "4                    60348      60.783333           91.2           28.0   \n",
       "\n",
       "   total_ann_pcp_x  avg_ann_pdsi_x  avg_ann_tmp_y  max_ann_tmp_y  \\\n",
       "0            49.01         -0.8475      64.141667           94.2   \n",
       "1            49.01         -0.8475      64.141667           94.2   \n",
       "2            40.29             NaN      24.041667           61.3   \n",
       "3            40.29             NaN      24.041667           61.3   \n",
       "4            10.37         -1.2725      60.783333           91.2   \n",
       "\n",
       "   min_ann_tmp_y  total_ann_pcp_y  avg_ann_pdsi_y  \n",
       "0           34.6            49.01         -0.8475  \n",
       "1           34.6            49.01         -0.8475  \n",
       "2          -11.6            40.29             NaN  \n",
       "3          -11.6            40.29             NaN  \n",
       "4           28.0            10.37         -1.2725  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(crime_data, household_income_data, on=['year', 'state'], how='inner')\n",
    "data = pd.merge(data, climate_df, on=['year', 'state'], how='inner')\n",
    "\n",
    "# display first 5 rows of resulting DataFrame\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75884c06-2b32-4828-9f7f-e553ffa63ad0",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "### What is it?\n",
    "Exploratory data analysis is the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca5f39-8fe0-4627-be42-98b4c0240ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4415119-3d4f-4b32-b89f-bbe38d57d873",
   "metadata": {},
   "source": [
    "## Works Cited\n",
    "FBI. “Variables Affecting Crime.” Uniform Crime Reporting Program, 2011, https://ucr.fbi.gov/hate-crime/2011/resources/variables-affecting-crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb60152d-284f-488b-9b76-b2180eb497fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
